---
title: "PLAN for Chapter 2. Simulation-estimation study for the temperate model"
subtitle: "This RMarkdown is a template as initially outlined in the progress report. Each task will be outlined and then followed by a code block to be completed."
output:
html_notebook:
number_sections: true
---

```{r setup}
# load("workspaces/Chapter_02_china_metropolis_2024-07-01 - 72hr lng.RData")
library(R.utils)
library(tidyverse)
library(rstan)
library(parallel)
library(patchwork)
library(pbmcapply)
library(pbapply)
library(memoise)
library(RColorBrewer)
library(ggtext)
source("../R/constants.R")
source("../R/load_functions.R")

rstan_options(auto_write = TRUE, threads_per_chain = 1)

n_cores = parallelly::availableCores()
options(mc.cores = n_cores)
message("Running on ", n_cores, " cores")

# Load model and metropolis algorithm (copied from VivaxODE project folder)
source(file = "../R/models/temperate_v11.R")
source(file = "../R/functions/adaptive_metropolis.R")
# Load priors for each scenario
source(file = "../R/priors.R")
my_state_init = state_init_3
start_time = Sys.time()
```
## Parameter recovery on real data

We test whether parameter recovery works on real datasets. We will find data from a variety of settings (e.g., transmission levels, remoteness, strains) to demonstrate generalisability.

Data:

- Hainan data (tropical China) but this has been difficult to acquire.
We will not be investigating Chinese Yunnan (southern mountainous) or Henan (central temperate) data which we do have because the Yunnan strain is not known to be tropical, and the Henan data is temperate (our current temperate model does not align with this data convincingly).
- Brazilian 'integrated data set', available per county or municipality and very detailed.

```{r}
china_selections = tribble(
  ~Region, ~min, ~max,
  "Dengzhou", "2004-01-01", "2009-01-01",
  "Guantang", "1977-01-01", "1982-01-01",
  "Huangchuan", NA, NA,
  "Xiayi", NA, NA
) %>%
  mutate(min = as.Date(min),
         max = as.Date(max))
```

```{r}
if (!require(MalariaData)) {
  china_data = read_rds("china_data.rds")
} else {
  library(MalariaData)
  regions = c("Xiayi", "Guantang", "Dengzhou", "Huangchuan") %>% setNames({.})
  china_data_all = lapply(regions, function(x) {load_region(x, species = "Vivax", source="Local")}) %>%
    bind_rows(.id = "Region") %>%
    select(Region, Date, Cases) %>%
    left_join(china_selections, by="Region") %>%
    mutate(Date = as.Date(paste(year(Date), month(Date), "01", sep="-")) + months(1) - days(1)) %>% # Align to last day of the month
    mutate(include = ifelse(Date >= min & Date < max, "grey20", "grey"),
           include = replace_na(include, "grey"))
  
  china_data = china_data_all %>%
    filter(include == "grey20") %>%
    select(-include)
  
  write_rds(china_data, "china_data.rds")
}
```

Now we fit the model for scenarios

```{r}
data_baseline = list(
  t0 = -30*years,
  gamma_d = 1/434.,
  gamma_l = 1/223,
  f = 1/72,
  r = 1/60,
  eps = 0
)
# Add each scenario's data on
data_scenarios = lapply(seq_len(nrow(scenarios)), function(i) {
  data_scenario = data_baseline
  scenario_specific = scenarios[i,]
  for (name in names(scenario_specific)) {
    if (!is.character(scenario_specific[[name]])) {
      data_scenario[[name]] = scenario_specific[[name]]
    }
  }
  data_scenario$y0 = my_state_init(data_scenario, I0=0.01)
  
  # Add case data
  region_name = scenario_specific$region
  ts_region = china_data %>%
    filter(Region == region_name)
  first_year = min(year(ts_region$Date))
  ts_region = ts_region %>%
    mutate(ts = as.numeric(Date - as.Date(paste0(first_year, "-01-01"))))
  data_scenario$ts = ts_region$ts
  data_scenario$cases = ts_region$Cases
  return(data_scenario)
}) %>%
  setNames(scenarios$name)
# data_scenarios = data_scenarios[c("baseline duration, baseline ascertainment, baseline phenotype, Dengzhou")]
```

Run

```{r, eval=F}
# Define inits - start at the mean of all scenarios and the mean sd of all chains
init = c(
  alpha = 0.173,
  beta = 0.899,
  lambda = 0.05,
  phi = 999,#1.42,
  kappa = 2.45,
  phase = 119,
  p_long = 0.775,
  p_silent = 0.245,
  p_RCI = 0.123
)

init_sd = c(alpha = 0.0296,
            beta = 0.0293,
            lambda = 0.0125,
            phi = 0.260,
            kappa = 0.395,
            phase = 5.20,
            p_long = 0.0836,
            p_silent = 0.0577,
            p_RCI = 0.0218)

samp_results = rep(list(NULL), length(data_scenarios)) %>%
  setNames(names(data_scenarios))
```

```{r, eval=F}
max_hours = 0.5
models = lapply(data_scenarios, make_model)
for (i in seq_len(length(data_scenarios))) {
  print(paste("Scenario", i))
  
  tictoc::tic()
  samp = metropolis_sampling(models[[i]],
                             init = init,
                             init_sd = init_sd,
                             data = data_scenarios[[i]],
                             n_iter = 500,
                             n_burnin = 400,
                             n_adapt = 100,
                             n_chains = 8,
                             time_limit = max_hours / length(data_scenarios))
  tictoc::toc()
  samp_results[[i]] = samp
}
samp_filename = paste0("samp_results_", Sys.Date(), ".rds")
saveRDS(samp_results, samp_filename)
```

Load simulations from HPC

```{r, eval=F}
rds_1 = read_rds("~/Desktop/Chapter_02_china_metropolis_2024-07-07.rds")
rds_2 = read_rds("~/Desktop/Chapter_02_china_metropolis_2024-07-09.rds")
samp_results = c(rds_1, rds_2)
```

Transform output parameters

```{r}
# inspect parameter posteriors
posterior_seasonal_1 = pblapply(samp_results, function(samp) {
  bind_cols(
    bind_rows(samp$sim),
    bind_rows(samp$sim_diagnostics, .id = "chain")
  ) %>%
    slice_sample(n = 1000) %>%
    pivot_longer(-c(iteration, accept, lpp, ll, chain), names_to = "parameter", values_to = "value")
}) %>%
  bind_rows(.id = "Scenario") %>%
  mutate(Scenario = fct_inorder(Scenario))#
posterior_seasonal_2 = posterior_seasonal_1 %>%
  group_by(Scenario, parameter)
x1 = scenarios %>%
  select(name, name_short, region)
posterior_seasonal = posterior_seasonal_2 %>%
  left_join(scenarios, by=c("Scenario" = "name")) %>%
  mutate(name_short = name_short %>% str_replace_all(", ", ",\n"))

resim = lapply(samp_results, function(samp) {
  resim = extract(samp, "incidence", n_samples=100, threading=F)
}) %>%
  bind_rows(.id = "Scenario") %>%
  mutate(Scenario = fct_inorder(Scenario)) %>%
  left_join(scenarios, by=c("Scenario" = "name")) %>%
  mutate(name_short = name_short %>% str_replace_all(", ", ",\n")) %>%
  pivot_longer(matches("^clinical"), names_to="metric") %>%
  mutate(metric = metric %>% case_match(
    "clinical_incidence" ~ "Total",
    "clinical_relapse" ~ "Relapse",
    "clinical_primary" ~ "Primary"
  ))

plot_original_data = lapply(data_scenarios, function(x) {
  tibble(time = x$ts,
         cases = x$cases)
}) %>%
  bind_rows(.id = "Scenario") %>%
  left_join(scenarios, by=c("Scenario" = "name")) %>%
  mutate(Scenario = fct_inorder(Scenario))

trace_plot = posterior_seasonal %>%
  filter(name_shortest == "Baseline") %>%
  ggplot(aes(x = iteration, y = value, color=Scenario, group=interaction(Scenario, chain))) +
  geom_step(alpha=0.25) +
  coord_cartesian(xlim = c(0, NA)) +
  scale_y_log10() +
  facet_wrap(vars(parameter), scales="free", labeller=plot_labeller_novar) +
  labs(subtitle = "Parameter traces")
trace_plot
filename = paste0("../plots/china_trace.png")
ggsave(filename, width=8, height=8)

var_plot = posterior_seasonal %>%
  ggplot(aes(x = value, fill=Scenario, color=Scenario)) +
  geom_density(alpha=0.5) +
  coord_cartesian(xlim = c(0, NA)) +
  facet_wrap(vars(parameter), scales="free", labeller=plot_labeller_novar) +
  labs(subtitle = "Parameter estimates")
var_plot
filename = paste0("../plots/china_variables.png")
# ggsave(filename, width=8, height=8)

ll_plot = posterior_seasonal %>%
  ggplot(aes(x = ll, y = name_shortest, color=name_shortest, fill=name_shortest, group=interaction(name_shortest))) +
  ggridges::geom_density_ridges(alpha=0.25) +
  scale_y_discrete(limits = rev) +
  facet_grid(cols=vars(region), scales="free_x") +
  labs(subtitle = "Log likelihood (higher is better)") +
  theme(legend.position = "none")
ll_plot
filename = paste0("../plots/china_loglikelihood.png")
ggsave(filename, width=8, height=8)

lpp_plot = posterior_seasonal %>%
  ggplot(aes(x = lpp, y = name_shortest, color=name_shortest, fill=name_shortest, group=interaction(name_shortest))) +
  ggridges::geom_density_ridges(alpha=0.25) +
  scale_y_discrete(limits = rev) +
  facet_grid(cols=vars(region), scales="free_x") +
  labs(subtitle = "Log posterior probability (higher is better)") +
  theme(legend.position = "none")
lpp_plot
filename = paste0("../plots/china_logposteriorprobability.png")
ggsave(filename, width=8, height=8)

bf_data = posterior_seasonal %>%
  group_by(name_short, name_shortest, n_changes) %>%
  summarise(# lpp = log(sum(exp(lpp))) - log(n()),
    lpp = matrixStats::logSumExp(lpp) - log(n()),
    # ll = mean(ll),
    ll = matrixStats::logSumExp(ll) - log(n()),
    .groups = "drop") %>%
  mutate(baseline_lpp = lpp[name_shortest == "Baseline"],
         baseline_ll = ll[name_shortest == "Baseline"],
         bayes_factor = exp(lpp - baseline_lpp)) %>%
  ungroup() %>%
  filter(name_shortest != "Baseline")

bf_plot = ggplot(bf_data, aes(x = bayes_factor, y = name_shortest, fill = name_shortest)) +
  geom_col(alpha = 0.8) +
  geom_vline(xintercept = 1, linetype="dashed") +
  scale_x_log10(labels = label_auto3, breaks = c(10 ^ c(-14, -7, seq(-2, 3, by=1)))) +
  scale_y_discrete(limits = rev) +
  ggforce::facet_col(vars(n_changes), scales="free_y", space="free") +
  theme(legend.position = "none",
        axis.text.x = element_markdown(angle=-90, hjust=0),
        axis.title.x = element_markdown(),
        strip.background = element_blank(),
        strip.text.x = element_blank(),
        strip.text.y = element_blank()) +
  labs(subtitle = "Bayes factor relative to the baseline model",
       x = "*K*",
       y = NULL)
bf_plot
filename = paste0("../plots/china_bayesfactor.png")
ggsave(filename, width=8, height=4)

# ggsave(filename, width=8, height=4)

# Plot credible intervals
epi_plot = ggplot(mapping = aes(x=time/years)) +
  geom_line(data = resim,
            aes(y=value, color=metric, group=interaction(metric, ix)),
            alpha = 0.1) +
  geom_point(data = plot_original_data,
             aes(y = cases, group = NULL, color=NULL),
             size = 0.5, alpha = 0.5) +
  scale_y_log10(labels = label_auto2) +
  # coord_cartesian(ylim = c(0, NA)) +
  # facet_wrap(vars(Scenario), scales="free_y") +
  facet_grid(rows=vars(name_shortest), cols=vars(region)) +
  labs(x = "Year",
       y = "Monthly incidence",
       color = "Infection type") +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))
epi_plot
filename = paste0("../plots/china_incidence.png")
ggsave(filename, width=8, height=8)

epi_plot / var_plot + theme(legend.position="none") + plot_annotation(tag_levels="A")
filename = paste0("../plots/china_posterior.png")
ggsave(filename, width=8, height=8)

resim_seasonality = pblapply(samp_results[1:2], function(samp) {
  t = seq(0, years, length.out=500)
  samp_sim = bind_rows(samp$sim)
  samp_rand = sample.int(nrow(samp_sim), 500)
  suitability_traces = lapply(samp_rand, function(ix) {
    samp_suitability = tibble(
      time = t,
      suitability = sapply(t, function(tt) {
        omega = suitability(tt, samp$data$eps, samp_sim[[ix, "kappa"]], samp_sim[[ix, "phase"]])
      })
    )
  }) %>%
    bind_rows(.id = "trace")
}) %>%
  bind_rows(.id = "Scenario") %>%
  left_join(scenarios, by=c("Scenario" = "name")) %>%
  mutate(Scenario = fct_inorder(Scenario))

resim_seasonality_plot = resim_seasonality %>%
  filter(scenario <= 2) %>%
  ggplot(aes(x = time, y = suitability, color = region, group = interaction(region, trace))) +
  geom_line(alpha = 0.05) +
  scale_x_continuous(breaks = seq(0, years, length.out=13), labels = c(month.abb, month.abb[1])) +
  labs(subtitle = "Posterior estimates of transmission seasonality",
       x = "Month",
       y = "Mosquito-borne transmission suitability",
       color = "Region") +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))
resim_seasonality_plot
filename = paste0("../plots/china_resim_seasonality_plot.png")
ggsave(filename, width=8, height=4)

rm(trace_plot)
rm(epi_plot)
rm(var_plot)
rm(ll_plot)
rm(lpp_plot)
rm(resim_seasonality_plot)
```

Parameter estimates

```{r}
lapply(samp_results[1:2], function(x) {
  bind_rows(x$sim)
}) %>%
  bind_rows(.id = "Scenario") %>%
  left_join(scenarios, by=c("Scenario" = "name")) %>%
  mutate(Scenario = fct_inorder(Scenario),
         phase = phase + years/4) %>%
  pivot_longer(c(kappa, phase)) %>%
  group_by(Scenario, region, name) %>%
  summarise(mean = mean(value),
            lower = quantile(value, 0.025),
            upper = quantile(value, 0.975),
            .groups = "drop") %>%
  mutate(summary = paste0(signif(mean, 3), " (", signif(lower, 3), ", ", signif(upper, 3), ")")) %>%
  select(region, name, summary)
```

Plot baseline

```{r}
# Get ranges
var_ranges = posterior_seasonal %>%
  filter(name_shortest == "Baseline") %>%
  group_by(parameter) %>%
  summarise(min = min(value),
            max = max(value))
var_priors = list()
baseline_model = models[[1]]
for (i in seq_len(nrow(var_ranges))) {
  parameter_name = var_ranges$parameter[i]
  parameter_min = 0 # var_ranges$min[i]
  parameter_max = var_ranges$max[i]
  parameter_range = parameter_max - parameter_min
  parameter_seq = seq(parameter_min, parameter_max, length.out = 100)
  prior = sapply(parameter_seq, function(x) {
    # insert range to evaluate prior over
    x_dummy = init
    x_dummy[parameter_name] = x
    exp(baseline_model$log_prior(x_dummy))
  })
  d_prior = prior / mean(prior) / parameter_range
  
  if (parameter_name == "p_long") {
    var_priors[["s"]] = tibble(value = 1-parameter_seq, prior = d_prior / max(d_prior))
  } else if (parameter_name == "p_silent") {
    var_priors[["p"]] = tibble(value = 1-parameter_seq, prior = d_prior / max(d_prior))
  } else {
    var_priors[[parameter_name]] = tibble(value = parameter_seq, prior = d_prior / max(d_prior))
  }
}

# Do transformation to align with s and p variable names
var_priors = bind_rows(var_priors, .id="parameter")
var_priors$value[var_priors$parameter == "p_long"] = 1 - var_priors$value[var_priors$parameter == "p_long"]
var_priors$parameter[var_priors$parameter == "p_long"] = "s"
var_priors$value[var_priors$parameter == "p_silent"] = 1 - var_priors$value[var_priors$parameter == "p_silent"]
var_priors$parameter[var_priors$parameter == "p_silent"] = "p"

baseline_var_plot_data = posterior_seasonal %>%
  filter(name_shortest == "Baseline")
baseline_var_plot_data$value[baseline_var_plot_data$parameter == "p_long"] = 1 - baseline_var_plot_data$value[baseline_var_plot_data$parameter == "p_long"]
baseline_var_plot_data$parameter[baseline_var_plot_data$parameter == "p_long"] = "s"
baseline_var_plot_data$value[baseline_var_plot_data$parameter == "p_silent"] = 1 - baseline_var_plot_data$value[baseline_var_plot_data$parameter == "p_silent"]
baseline_var_plot_data$parameter[baseline_var_plot_data$parameter == "p_silent"] = "p"

baseline_var_plot = baseline_var_plot_data %>%
  ggplot(aes(x = value, fill=region, color=region)) +
  geom_density(aes(y=..scaled..), alpha=0.5) +
  geom_line(data=var_priors, aes(y=prior, fill=NULL, color=NULL), linetype="dashed") +
  coord_cartesian(xlim = c(0, NA)) +
  facet_wrap(vars(parameter), scales="free", labeller=plot_labeller_novar) +
  labs(subtitle = "Posterior parameter estimates",
       x = NULL,
       y = "Scaled density",
       color = "Region",
       fill = "Region") +
  theme(strip.text = element_markdown(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
baseline_var_plot
filename = paste0("../plots/china_baseline_variables.png")
# ggsave(filename, width=8, height=8)

baseline_epi_plot = resim %>%
  filter(scenario <= 2) %>%
  ggplot(aes(x=time/years)) +
  geom_line(aes(y=value, color=metric, group=interaction(metric, ix)),
            alpha = 0.1) +
  geom_point(data = plot_original_data,
             aes(y = cases, group = NULL, color=NULL),
             size = 0.5, alpha = 0.5) +
  scale_y_log10(labels = label_auto2) +
  # coord_cartesian(ylim = c(0, NA)) +
  # facet_wrap(vars(Scenario), scales="free_y") +
  facet_grid(cols=vars(region)) +
  labs(x = "Year",
       y = "Monthly incidence",
       color = "Infection type",
       subtitle = "Modelled mean incidence") +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))
baseline_epi_plot
filename = paste0("../plots/china_baseline_epi.png")
# ggsave(filename, width=8, height=8)

baseline_var_plot / baseline_epi_plot +
  plot_layout(heights = c(2, 1)) +
  plot_annotation(tag_levels = "A")
filename = paste0("../plots/china_baseline.png")
ggsave(filename, width=8, height=8)

rm(baseline_var_plot)
rm(baseline_epi_plot)
```

Check acceptance

```{r}
accept = lapply(samp_results, function(x) {
  mean(unlist(x$accept))
})

ess = lapply(samp_results, function(x) {
  x$ESS %>% unlist %>% matrix(ncol=9, byrow=T) %>% colSums() %>% setNames(names(x$ESS[[1]]))
})
ess_df = bind_rows(ess, .id = "scenario") %>%
  pivot_longer(-scenario, names_to="parameter", values_to="ess") %>%
  left_join(scenarios, by=c("scenario" = "name"))
ess_df$parameter[ess_df$parameter == "p_long"] = "s"
ess_df$parameter[ess_df$parameter == "p_silent"] = "p"

ess_plot = ggplot(ess_df, aes(x = ess, y = parameter, fill = region)) +
  geom_vline(xintercept=100, linetype="dashed") +
  geom_col(alpha = 0.8, position="dodge2") +
  # coord_cartesian(xlim=c(0, 500)) +
  scale_x_log10(labels = scales::label_number()) +
  scale_y_discrete(limits=rev, breaks = sort(unique(ess_df$parameter)), labels = make_greek(sort(unique(ess_df$parameter)))) +
  facet_wrap(vars(name_shortest)) +
  # theme(legend.position = "none") +
  labs(subtitle = "Effective sample size accounting for autocorrelation (higher is better)",
       x = "ESS",
       y = "Parameter",
       fill = NULL) +
  theme(axis.text.y = element_markdown(),
        legend.position = "none")

rhat = pbmclapply(samp_results, rhat.metropolisfit)
rhat_df = bind_rows(rhat, .id = "scenario") %>%
  pivot_longer(-scenario, names_to="parameter", values_to="rhat") %>%
  left_join(scenarios, by=c("scenario" = "name"))
rhat_df$parameter[rhat_df$parameter == "p_long"] = "s"
rhat_df$parameter[rhat_df$parameter == "p_silent"] = "p"

rhat_plot = ggplot(rhat_df, aes(x = rhat, y = parameter, fill = region)) +
  geom_vline(xintercept=1.05, linetype="dashed") +
  geom_col(alpha = 0.8, position="dodge2") +
  scale_y_discrete(limits=rev, labels=make_greek) +
  facet_wrap(vars(name_shortest)) +
  # theme(legend.position = "none") +
  labs(subtitle = "Chain convergence criteria (lower is better)",
       x = latex2exp::TeX("$\\hat{r}$"),
       y = "Parameter",
       fill = NULL) +
  theme(axis.text.y = element_markdown())

ess_plot / rhat_plot +
  plot_annotation(tag_levels = "A") + plot_layout(guides="collect") & theme(legend.position = "bottom")
filename = paste0("../plots/china_mcmc_diagnostics.png")
ggsave(filename, width=8, height=10)
```


Save workspace

```{r}
end_time = Sys.time()
print(end_time)
print(end_time - start_time)
workspace_filename = paste0("workspaces/Chapter_02_china_metropolis_", Sys.Date(), ".RData")
save.image(workspace_filename)
beepr::beep()
```

Misc - improve guess by starting at the mean

```{r}
mean_posterior_seasonal = posterior_seasonal %>%
  group_by(parameter) %>%
  summarise(median = median(value)) %>%
  mutate(parameter = fct_relevel(parameter, names(init))) %>%
  arrange(parameter)

sd_posterior_seasonal = posterior_seasonal %>%
  group_by(parameter, scenario) %>%
  summarise(sd = sd(value)) %>%
  summarise(med_sd = median(sd)) %>%
  mutate(parameter = fct_relevel(parameter, names(init))) %>%
  arrange(parameter)
```
